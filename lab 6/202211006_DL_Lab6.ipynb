{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CTNISaUwu9BB",
        "AqCJL-KA-S0Y"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries "
      ],
      "metadata": {
        "id": "uL96DMe4u-jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLm6dvkuCZmk",
        "outputId": "9715d5d9-c6d0-432e-c1c9-6cec13dd95ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from opencv-python) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f2jNNxsBsO4I"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST dataset"
      ],
      "metadata": {
        "id": "CTNISaUwu9BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
      ],
      "metadata": {
        "id": "XO4V8Immu9ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data shape:\", train_images.shape, train_labels.shape)\n",
        "print(\"Testing data shape:\", test_images.shape, test_labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bol2HI3tvJSZ",
        "outputId": "9caf9c9a-b9c1-4086-8e21-f782d61426f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 28, 28) (60000,)\n",
            "Testing data shape: (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the pixel values \n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n"
      ],
      "metadata": {
        "id": "sX660IlsvLFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoded to one hot encoded labels\n",
        "num_classes = 10 \n",
        "y_train = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "metadata": {
        "id": "2egGhA-cv0TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_images[15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "as0xptarvetX",
        "outputId": "2dce5811-5a1f-420f-f170-9c30a8b09057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f63eab442b0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Architecture \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "4is_5KtKwWw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WAZBhDvxw4q",
        "outputId": "8bc60930-57ab-49f6-ac28-2db1da56598d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and compiling the model \n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "model.fit(train_images.reshape(-1, 28, 28, 1),y_train,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6HtP0U5wlvY",
        "outputId": "5a2891e8-abb9-45db-902f-f46de64d1591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 65s 34ms/step - loss: 0.5090 - accuracy: 0.8147\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 61s 33ms/step - loss: 0.3307 - accuracy: 0.8797\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 61s 32ms/step - loss: 0.2817 - accuracy: 0.8964\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.2481 - accuracy: 0.9101\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 75s 40ms/step - loss: 0.2242 - accuracy: 0.9174\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 61s 32ms/step - loss: 0.2040 - accuracy: 0.9248\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1865 - accuracy: 0.9315\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1702 - accuracy: 0.9383\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.1571 - accuracy: 0.9411\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 59s 32ms/step - loss: 0.1421 - accuracy: 0.9462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63eaa69610>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images.reshape(-1, 28, 28, 1), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YE316uRw2wp",
        "outputId": "044ba7ed-c172-4127-add9-eec63b1a2eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2888 - accuracy: 0.9067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BwH4W9mxsVZ",
        "outputId": "1888f093-0412-4df2-c5b5-b5f2f626e666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9067000150680542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"FMnist.h5\")"
      ],
      "metadata": {
        "id": "lUdl4eZbzT86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linneaus_5 Dataset"
      ],
      "metadata": {
        "id": "7Zf7fqFM-MUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This dataset was taking too long to train. Therefore, I decided to use gpu from colab to train the model**  "
      ],
      "metadata": {
        "id": "vbk52JLuDWgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/DL_DATA/Linnaeus_5\""
      ],
      "metadata": {
        "id": "9G9QsrRI7K2x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With RGB Images"
      ],
      "metadata": {
        "id": "AqCJL-KA-S0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_train = ImageDataGenerator(\n",
        "    rescale=1./255, # rescale pixel values between 0 and 1\n",
        "    rotation_range=20, # randomly rotate images within 20 degrees\n",
        "    width_shift_range=0.1, # randomly shift images horizontally by 10%\n",
        "    height_shift_range=0.1, # randomly shift images vertically by 10%\n",
        "    shear_range=0.1, # randomly apply shearing transformations\n",
        "    zoom_range=0.1, # randomly zoom in on images\n",
        "    horizontal_flip=True, # randomly flip images horizontally\n",
        ")\n",
        "\n",
        "gen_test = gen_train = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = gen_train.flow_from_directory(path+\"/train\", batch_size = 64, class_mode = 'categorical', target_size = (32, 32))\n",
        "test_gen = gen_test.flow_from_directory(path+\"/test\", batch_size = 64, class_mode = 'categorical', target_size=(32, 32))"
      ],
      "metadata": {
        "id": "vcn96D2xzZ9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfeca394-da24-40d2-ea87-33a9f17a1b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6000 images belonging to 5 classes.\n",
            "Found 2000 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  model = keras.Sequential([\n",
        "      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "      layers.MaxPooling2D((2, 2)),\n",
        "      layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      layers.MaxPooling2D((2, 2)),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(32, activation='relu'),\n",
        "      layers.Dense(5, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  history = model.fit(train_gen, steps_per_epoch = 40, epochs = 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOGJVxCh9H-o",
        "outputId": "aba6cb27-489f-4c15-d142-d5e13f8137b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 334s 8s/step - loss: 1.5446 - accuracy: 0.2613\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 167s 4s/step - loss: 1.4767 - accuracy: 0.3251\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 106s 3s/step - loss: 1.4108 - accuracy: 0.3789\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 56s 1s/step - loss: 1.2851 - accuracy: 0.4513\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 33s 824ms/step - loss: 1.1809 - accuracy: 0.5020\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 15s 362ms/step - loss: 1.1439 - accuracy: 0.5250\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 11s 273ms/step - loss: 1.0727 - accuracy: 0.5688\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 10s 254ms/step - loss: 1.0686 - accuracy: 0.5645\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 1.0170 - accuracy: 0.5932\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 7s 165ms/step - loss: 1.0418 - accuracy: 0.5853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  history1 = model.fit(train_gen, steps_per_epoch = 40, epochs = 10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeAON0l4GRQF",
        "outputId": "bcc417b8-da25-43ce-d7a9-cf2744cebc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.9641 - accuracy: 0.6160\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 5s 113ms/step - loss: 0.9702 - accuracy: 0.6141\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 4s 109ms/step - loss: 0.9400 - accuracy: 0.6238\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.8829 - accuracy: 0.6572\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 5s 114ms/step - loss: 0.8780 - accuracy: 0.6488\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 4s 109ms/step - loss: 0.8718 - accuracy: 0.6629\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.8344 - accuracy: 0.6730\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 5s 113ms/step - loss: 0.8936 - accuracy: 0.6513\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 4s 107ms/step - loss: 0.7956 - accuracy: 0.6832\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 4s 103ms/step - loss: 0.7939 - accuracy: 0.6910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  history2 = model.fit(train_gen, steps_per_epoch = 40, epochs = 20)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhLBLpsFGjM5",
        "outputId": "080c0a68-871a-4c2c-e27d-dce9fd1c3ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "40/40 [==============================] - 4s 105ms/step - loss: 0.7410 - accuracy: 0.7146\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 4s 109ms/step - loss: 0.7102 - accuracy: 0.7203\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.6497 - accuracy: 0.7524\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 4s 106ms/step - loss: 0.6441 - accuracy: 0.7625\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 4s 107ms/step - loss: 0.5969 - accuracy: 0.7773\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 4s 108ms/step - loss: 0.6051 - accuracy: 0.7676\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 4s 112ms/step - loss: 0.5573 - accuracy: 0.7863\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - 4s 109ms/step - loss: 0.5682 - accuracy: 0.7750\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.5123 - accuracy: 0.8148\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - 4s 107ms/step - loss: 0.4398 - accuracy: 0.8404\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.4653 - accuracy: 0.8204\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4465 - accuracy: 0.8353\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - 6s 140ms/step - loss: 0.4166 - accuracy: 0.8523\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.4084 - accuracy: 0.8469\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - 4s 105ms/step - loss: 0.3789 - accuracy: 0.8660\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.3373 - accuracy: 0.8695\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.3126 - accuracy: 0.8902\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - 4s 105ms/step - loss: 0.2881 - accuracy: 0.9021\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 0.2690 - accuracy: 0.9068\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - 4s 104ms/step - loss: 0.2673 - accuracy: 0.9059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MBrutWM9qYB",
        "outputId": "49c6f04c-8beb-4329-fbdf-c732d57107db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               295040    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324,933\n",
            "Trainable params: 324,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"L5RGB_.h5\")"
      ],
      "metadata": {
        "id": "BSlNjIzO_uYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Grayscale Images"
      ],
      "metadata": {
        "id": "t93EhWzl-WBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# define the root directory that contains the different image directories\n",
        "root_dir = path+'/train'\n",
        "\n",
        "# initialize empty lists for images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# loop through each subdirectory in the root directory\n",
        "for subdir in os.listdir(root_dir):\n",
        "    # define the subdirectory path\n",
        "    subdir_path = os.path.join(root_dir, subdir)\n",
        "    # loop through each file in the subdirectory\n",
        "    for filename in os.listdir(subdir_path):\n",
        "        # define the file path\n",
        "        file_path = os.path.join(subdir_path, filename)\n",
        "        # read the image using OpenCV\n",
        "        img = cv2.imread(file_path)\n",
        "        # convert the image to grayscale\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        # append the image to the list\n",
        "        images.append(img)\n",
        "        # append the label to the list\n",
        "        labels.append(subdir)\n",
        "        \n",
        "# convert the lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# perform label encoding on the string labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# perform one-hot encoding on the numerical labels\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "# print the shape of the arrays\n",
        "print('Shape of images array:', images.shape)\n",
        "print('Shape of labels array:', labels.shape)\n"
      ],
      "metadata": {
        "id": "wWuwtQ_4Iz_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970b105a-c35c-4dc3-f804-c2a404ba51a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images array: (6000, 32, 32)\n",
            "Shape of labels array: (6000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  model1 = keras.Sequential([\n",
        "      layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
        "      layers.MaxPooling2D((2, 2)),\n",
        "      layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      layers.MaxPooling2D((2, 2)),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(32, activation='relu'),\n",
        "      layers.Dense(5, activation='softmax')\n",
        "  ])\n",
        "  model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  history = model1.fit(images,labels, steps_per_epoch = 40, epochs = 25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdAGD1dNEY_M",
        "outputId": "dc029241-af2f-4f15-d225-e2b334f66ad0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "40/40 [==============================] - 2s 7ms/step - loss: 4.0697 - accuracy: 0.2073\n",
            "Epoch 2/25\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 1.5763 - accuracy: 0.2705\n",
            "Epoch 3/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.5040 - accuracy: 0.3283\n",
            "Epoch 4/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.4505 - accuracy: 0.3675\n",
            "Epoch 5/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.3967 - accuracy: 0.3937\n",
            "Epoch 6/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.3487 - accuracy: 0.4198\n",
            "Epoch 7/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.2891 - accuracy: 0.4577\n",
            "Epoch 8/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.2454 - accuracy: 0.4798\n",
            "Epoch 9/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.1552 - accuracy: 0.5262\n",
            "Epoch 10/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.0932 - accuracy: 0.5560\n",
            "Epoch 11/25\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 1.0145 - accuracy: 0.5887\n",
            "Epoch 12/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.9282 - accuracy: 0.6272\n",
            "Epoch 13/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.8356 - accuracy: 0.6755\n",
            "Epoch 14/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.7808 - accuracy: 0.6967\n",
            "Epoch 15/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.7205 - accuracy: 0.7242\n",
            "Epoch 16/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6735 - accuracy: 0.7427\n",
            "Epoch 17/25\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7712\n",
            "Epoch 18/25\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5084 - accuracy: 0.8120\n",
            "Epoch 19/25\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8302\n",
            "Epoch 20/25\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4383 - accuracy: 0.8373\n",
            "Epoch 21/25\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3713 - accuracy: 0.8715\n",
            "Epoch 22/25\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.3287 - accuracy: 0.8810\n",
            "Epoch 23/25\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2890 - accuracy: 0.9022\n",
            "Epoch 24/25\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2754 - accuracy: 0.9073\n",
            "Epoch 25/25\n",
            "40/40 [==============================] - 0s 9ms/step - loss: 0.2593 - accuracy: 0.9148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "-8jT-5CVEZcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bd27dd-4ad5-4aee-d59e-15c68e715711"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               295040    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324,357\n",
            "Trainable params: 324,357\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"L5GS.h5\")"
      ],
      "metadata": {
        "id": "f_TBkWKMEdvx"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}